---

layout:     post
title:      高级数据结构（三）
subtitle:   哈希表与一致性哈希
date:       2020-02-03 10:00:00
author:     "Remilia Scarlet"
header-img: "2020/06/06/t6XpBn.jpg"
catalog: true
mathjax: true
tags:
    - 数据结构
---

# 哈希表

[哈希表（Hash Table）](https://baike.baidu.com/item/%E5%93%88%E5%B8%8C%E8%A1%A8/5981869)是经典的[键值存储（Key-Value）](https://img.xileso.top/baike-%E9%94%AE-%E5%80%BC%E5%AD%98%E5%82%A8)数据结构, 其特点是随机访问时需要先通过**哈希函数**计算每个键所对应的哈希值, 再通过**索引映射函数**得到其在哈希表中的真实索引, 最后根据索引得到对应的值.

令哈希函数为$hash()$, 索引映射函数为$index()$, 则在给定的哈希表$T$中, 得到键$k$所对应的值$v$的过程可以描述如下:

\begin{equation}
k_{hash} = hash(k)
\end{equation}

\begin{equation}
k_{index} = index(k_{hash})
\end{equation}

\begin{equation}
T[k] = T.get(k_{index}) = v
\end{equation}

其中, $index()$的实现方式与哈希表的结构和**哈希冲突**的解决方法有关. 以链地址形式的哈希表为例, $index()$首先会对$k_{hash}$以数组长度取模得到对应链表的首地址, 然后通过遍历该链表得到真实值.

哈希表的设计思路是**空间换时间**, 令$T$为节点数量为$s$的哈希表, 设其中非空节点的数量为$m$, 则**负载因子（Load Factor）**可按照如下公式计算:

\begin{equation}
F_{load} = m/s
\end{equation}

相比于空间利用率接近100%的[红黑树](https://zhuanlan.zhihu.com/p/31805309)来说, 哈希表会在负载因子大于阈值时进行扩容并重新映射所有数据, 这样能保证插入和查找数据的时间复杂度尽不会随着哈希冲突出现的次数而显著增加. 设计良好的哈希表能够以$O(1)$时间复杂度实现对数据的查找, 但如果使用的哈希函数无法有效地让键离散化, 那么严重的哈希冲突会导致哈希表的查找时间复杂度退化为$O(n)$的线性表或$O(logn)$的红黑树.

## 常用哈希算法

哈希函数是基于[哈希算法](https://www.zhihu.com/question/26762707)实现的[单向函数](https://baike.baidu.com/item/%E5%8D%95%E5%90%91%E5%87%BD%E6%95%B0), 其特点是输入为无限空间内的任意对象, 但输出却被限定为有限空间内指定长度的整数, 并且很难通过结果推算出原始输入. 哈希算法的这些特点让其在[密码学](https://www.esat.kuleuven.be/cosic/publications/article-1532.pdf)、[数据校验](https://baike.baidu.com/item/MD5)、[负载均衡](https://www.bilibili.com/video/BV1Hs411j73w)等领域得到了广泛的应用. 根据[PlanetMath](https://planetmath.org/hashing)中的定义, 优秀的哈希算法应该满足以下性质:

**防碰撞 -** 理想情况下的哈希函数应属于[单射](https://baike.baidu.com/item/%E5%8D%95%E5%B0%84), 即对$\forall x,y \in $输入空间, 在$x \neq y$的情况下都满足$hash(x) \neq hash(y)$. 然而在实际应用中, 哈希函数的输入空间一般远大于输出空间, 因此根据[抽屉原理](https://baike.baidu.com/item/%E6%8A%BD%E5%B1%89%E5%8E%9F%E7%90%86/233776), 在输入的数据足够多的情况下必然会发生碰撞.

在哈希表中, 可以通过开放地址法或链地址法处理发生冲突的数据; 而在安全性要求较高的密码学领域, 攻击者一旦掌握了构造哈希冲突数据的方法就能够轻易破解加密信息, 因此目前常用的加密哈希算法在设计时都提升了破解所需要的成本, 例如: Google提出的SHA-1破解方法需要在单个GPU上运算100年左右, 而暴力破解比特币所使用的SHA-256算法则需要在单个矿机上运行数十亿年.

但在输入值的范围能够事先能够确定的场景下, 例如: 通过"姓名+身份证号"查询考试信息, 则可以构造不会发生冲突的**完美哈希**. 这类场景的特点是输入空间小于等于输出空间, 即满足单射成立的必要条件. GNU提供了[gperf](https://www.gnu.org/software/gperf/)工具用于获取完美哈希函数.

**防篡改 -** 被用于数据校验的哈希算法需要满足对数据敏感的性质, 即使微小的输入变化也应该让输出的结果显著不同. 例如: 在拥有大量不可信机器的[对等网络](https://baike.baidu.com/item/%E5%AF%B9%E7%AD%89%E7%BD%91%E7%BB%9C)中下载数据时, 为了防止数据出错导致整个文件被重新下载, 需要将大文件分割为4K大小的数据块. 在下载数据之前需要先从可信数据源获取正确的**根哈希**, 然后下载由每个块对应的哈希值所构成的哈希表, 对哈希表中所有哈希值按顺序拼接成的字符串再次哈希, 并将其与根哈希对比就可以验证表中数据的正确性, 从而验证整个文件的正确性. 这种通过[墨克树](https://img.xileso.top/wiki/%E5%93%88%E5%B8%8C%E6%A0%91)校验大文件的方法还被应用于数字货币区块信息的防篡改中.

尽管安全哈希算法（Secure Hash Algorithm, SHA）是不可逆的, 但通过暴力枚举构建[彩虹表](https://www.zhihu.com/question/19790488)或其他类似的手段仍然能够实现信息窃取, 例如: [针对SHA-1和MD5的反向查询网站](https://www.cmd5.com/). 目前Git仍在使用SHA-1来计算每次提交的唯一标识和数据校验凭证, 尽管在构造哈希值时使用了元信息混淆, 但由于SHA-1算法的破解成本日趋降低, Git从2.2版本开始考虑逐步向更安全的SHA-256算法迁移, 更多细节参见[Linus对Git安全性的回应](https://public-inbox.org/git/CA+dhYEViN4-boZLN+5QJyE7RtX+q6a92p0C2O6TA53==BZfTrQ@mail.gmail.com/T/).

**高效率:** 之前提到的SHA和MD都属于加密哈希算法, 特点是计算复杂但安全性较高. 然而在哈希表中一般不需要考虑安全性, 并且每次查找、插入、删除都需要计算哈希值, 因此在设计哈希算法时应该侧重于提升计算效率. Redis中对证书

以JDK中的, 常用的**位运算**和
另一种常用的方法是**缓存**哈希值结果, 在哈希表中经常有某些热点数据

这就需要结合等技巧来设计高效的哈希算法.

特点是安全性要求高, 但在哈希表中,, 因此需要考虑计算效率, 位运算和因此最好加缓存, 由于不需要考虑安全性, 这些哈希算法一般都是公开的.

例子

其中, **计算效率**与结果的**离散程度**是评价哈希表所使用的哈希函数的最重要标准.

好的哈希函数能够让映射的结果尽量分散

最近看到mysql的hash表，发现一个特点。
当hash表满的时候，hash表size总是扩展成一个素数

假设hash表大小为size，这是一个合数，即有size=a*n。当有hash值为hashcode，且hashcode = b*n.
则hashcode取模之后为
hashcode = hashcode%size = hashcode - (hashcode / size) *size = hashcode - (b/a)* size
因为a是固定的，那么上面的hashcode的取值只有b种可能，这样显然会增加冲突的概率。

函数设计得好就不用对质数取模, JDK用的算

## 哈希冲突解决方案

首先计算概率

分离链表: JDK, redis, Python中的实现方案. 实现简单, 占空间, 数组, 连续地址空间, 随机寻址容易, 插入删除费劲; 链表地址不连续, 随机寻址费劲, 插入删除容易; 链表遍历的时间复杂度O(n), 红黑树遍历时间复杂度O(logn)

注意: 算法导论里提到过, 当n非常大时, 任意底数的logn只相差常数倍, O(logn)已经可以表达所有底数的对数

开放定址法：(特例: 完美哈希, 如果事先知道所有的键值对且不需要运行时插入和删除)
开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。尽管写入逻辑简单, 但读取时逻辑及其复杂, 唯一的优点是节省空间

链地址法
将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。

再哈希法
当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。

建立公共溢出区
将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。

## 哈希表结构优化

Python3.7版本之后的字典结构要优于普通哈希表, 因为他的索引是整数, 哈希值和kv存在链表里, 只需要对整数数组做rehash, 因此数据量特别大的时候效率也不会明显降低

实现字典

JDK的优化 完全随即hash的情况下, 每个节点所对应的list的长度服从泊松分布, 大于8时概率为0.0000006, 转换为红黑树, 节省空间

求hash时用位运算加速

负载因子, 为什么选0.75, 最优解是ln2也就是0.693

令事件A为节点$Q$被插入数据, 则在完全随机生成哈希值的情况下, 每次向$T$中添加数据时事件A发生的概率为:

\begin{equation}
P_A=\frac{1}{s}
\end{equation}

现在向$T$中添加$n$个数据, 用$X$表示这$n$次独立重复的实验中事件A发生的次数, 显然服从[二项分布](https://baike.baidu.com/item/%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83):

\begin{equation}
P_{X=k} = C(n, k)P_A^k(1-P_A)^{n-k}
\end{equation}

那么$n$次实验中事件A恰好发生0次的概率为:

\begin{equation}
P_{X=0} = (\frac{s-1}{s})^{n}
\end{equation}

这个对于节点$Q$成立的结论可以推广到$T$中的所有节点, 为了保证

当添加数据的数量小于$log(2)/log(s/(s - 1))$时, 满足$P_{X=0}>0.5$来保证CPU分支预测时缓存的命中率, 也就是让不发生哈希冲突的概率大于发生

因此代入

现在问题就转化为求

由于CPU中分支预测的阈值为0.5, 因此

每个节点被插入的概率为$P=\frac{1}{s}$

则$n$次, 事件A恰好发生0次的概率:

每次插入新键时每个节点

每个节点发生哈希冲突的概率服从二项分布, 而每个节点发生哈希冲突的次数服从泊松分布. 那么我们

\begin{equation}
P(0) = C(n, 0) * 1/s
\end{equation}

相比于空间利用率

是一种空间换时间的数据结构, 能够有效查找数据

# 一致性哈希

应用场景: 缓存集群的负载均衡

例如: 3千万张图片, N台缓存服务器组成集群

server_num = hash(img_name) % N

添加服务器, N变化时, 同一张图片的server_num的值会变化, 所有的缓存都要重新配置

设计一种动态伸缩算法 增加或删除服务器时对原有系统的改动有限 降低维护成本 只需要修改修改哈希环上的下一个真实节点的缓存数据 而普通取模算法则需要修改全部服务器

## 哈希环与虚拟节点

理想情况 均匀分布 映射到2^32哈希环中

图1:

但实际上分布不均匀 哈希偏置
而且某台服务器突然宕机会导致下一个节点承受双倍流量
所以引入虚拟节点

图2:

## 实现细节

用python模拟实现负载均衡
map 红黑树 保证插入有序

寻找大于当前hash值的第一个节点

注意处理边界

# 参考内容

* [Hash Tables via USTC](http://staff.ustc.edu.cn/~csli/graduate/algorithms/book6/chap12.htm)
* [History of Hash Functions](https://www.esat.kuleuven.be/cosic/publications/article-1532.pdf)
