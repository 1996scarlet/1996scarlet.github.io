---

layout:     post
title:      深入理解数据结构（二）
subtitle:   序列的排序与查找
date:       2020-02-02 12:00:00
author:     "Remilia Scarlet"
header-img: "2020/06/06/t6XpBn.jpg"
catalog: true
mathjax: true
tags:
    - 数据结构
---

在任何一本数据结构教材中, 排序与查找都会被当做最基础的算法来介绍. 对序列型结构而言, 熟练掌握高性能排序与查找算法将显著提升业务处理效率. 在本节中, 我们将从Python为序列类型提供的`sort`方法以及针对所有可迭代对象的`sorted`高阶函数入手, 探索其内部实现的[TimSort](https://hackernoon.com/timsort-the-fastest-sorting-algorithm-youve-never-heard-of-36b28417f399)算法与常见的快速排序算法之间的差异. 而在查找算法方面, 本节将通过大量案例介绍双指针技巧和二分查找在序列结构中的应用. 但在实现上述算法之前, 需要先掌握切片的高级用法以及视图与拷贝的区别.

# 切片

所有内置序列类型都支持切片操作. 在可变序列中, 可以通过直接给切片赋值的方式修改元素的值甚至是数量, 而对不可变序列的切片赋值则会抛出异常.

```python
a, b = [1, 2, 3], "123"

a[2:] = []  # 修改后: [1, 2]
b[:2] = ""  # TypeError
```

切片的本质是`slice`类的实例, 该类的构造函数`slice(start, stop[, step])`接收三个参数, 分别为起始索引、结束索引以及步长. 当索引为负数时表示从后向前计算索引, 当步长为负数时表示从后向前提取数据. 参数之间用`:`分隔, 且参数具有默认值. 步长默认为1, 当步长为正数时, 起始索引为0, 结束索引为序列的长度; 当步长为负数时, 起始索引对应序列的最后一个元素, 结束索引为特殊值, 恰好指向第一个元素的前一个位置. 值得注意的是, 切片提取元素的规则是**包含起始索引但不包含结束索引**.

```python
s[:2:-1]  # 从最后一个元素到索引为2的元素的反转
s[-5:9:2]  # 从倒数第5个到正数第9个 步长为2
s[::-1]  # 生成序列的反转
```

默认情况下, 对象后紧跟着的方括号`[...]`中的内容会被传递给该`__getitem__`方法. 这意味着索引和切片的参数都会被传递到该方法中.

```python
class MySeq:
    def __getitem__(self, index):
        if isinstance(index, slice):
            print(f"slice: {index}")
        elif isinstance(index, int):
            print(f"index: {index}")
        else:
            msg = f"{type(self)} indices must be integers"
            raise TypeError(msg)

s = MySeq()
s[9]  # index: 9
s[::-1]  # slice: slice(None, None, -1)
s["key"]  # TypeError
```

上述例子中使用的切片都属于匿名切片, 是为了方便切片的使用而提供的特殊语法, 每次通过方括号切片时都会生成匿名的`slice`对象. 大量的硬编码切片不仅会显著降低代码的可维护性, 频繁地创建与销毁匿名对象也会增加解释器的执行负担. 一种行之有效的改进方案是给需要重复使用的切片命名.

```python
record = '....................100 .......513.25 ..........'
SHARES = slice(20, 23)
PRICE = slice(31, 37)
cost = int(record[SHARES]) * float(record[PRICE])
```

通过切片查看序列中的元素则仅会返回对应内存区域的视图, 一旦发生赋值操作, 解释器会让被赋值的变量名指向当前切片区域的**浅拷贝**, 即仅拷贝容器的结构以及内部元素的引用. 使用容器的构造函数或切片都只能获得浅拷贝副本.

```python
a = list(range(5))  # [0, 1, 2, 3, 4]
b = a[2:4]  # [2, 3] 浅拷贝只复制引用
b[0] += 1
print(a)  # [0, 1, 3, 3, 4]
# a[2]和b[0]所指向的内存被修改

c = list(a)  # 浅拷贝
d = a[:]  # 浅拷贝

a is a[:]  # False 浅拷贝会生成新的结构
```

浅拷贝的优势在于只复制结构以及引用, 对于不可变序列来说, 这显著提升了内存利用率. 与之相对的**深拷贝**则会复制所有的引用并递归地拷贝这些引用所对应的内存数据, 尽管这样做能够防止派生出的变量意外地修改原始序列的值, 但却会显著提升内存占用量.

```python
from copy import deepcopy

a = [[j for j in range(i)] for i in range(1, 4)]
b = deepcopy(a[1:])  # 复制引用以及指向的内存

b[0][0] += 1  # [[1, 1], [0, 1, 2]]
print(a)  # [[0], [0, 1], [0, 1, 2]]  没有变化
```

熟练使用切片操作能够显著提升编码效率, 例如解决[数组原地移位](https://leetcode-cn.com/problems/rotate-array/)问题. 首先看常规方法, 即通过多次反转数组实现原地移位.

```python
def rotate(self, nums: List[int], k: int) -> None:
    def rev(entry, start, end):
        while start < end:
            entry[start], entry[end] = entry[end], entry[start]
            start += 1
            end -= 1

    n = len(nums)
    k %= n

    rev(nums, 0, n-1)  # 反转
    rev(nums, 0, k-1)  # 再次反转前k位
    rev(nums, k, n-1)  # 再次反转剩余数据
```

使用切片则可以显著减少代码量, 而且也更有利于理解, 尽管这会产生中间变量.

```python
def rotate(self, nums: List[int], k: int) -> None:
    k %= len(nums)
    nums[:] = nums[-k:] + nums[:-k]
```

在上述代码中, 列表旋转的结果被赋值给`nums[:]`, 这是因为题目要求对列表进行原地修改. 尽管`nums`和`nums[:]`的打印结果完全相同, 但二者却是截然不同的对象. `nums`是变量名, 它指向存储序列结构的内存区域, 直接对其赋值等价于让其指向新的序列, 因此无法实现原地修改; 而`nums[:]`的本质是切片, 即方法`__getitem__(slice(None))`返回的结果, 它代表的就是序列所包含的所有引用（由于是被赋值对象因此只是视图而不是浅拷贝）, 对`nums[:]`赋值会覆盖这些引用, 因此能够实现原地修改. 这些细微的区别会导致算法的输出结果出现巨大差异, 尤其是给函数传递参数时.

# 排序

作为计算机科学领域最基本的研究问题之一, 排序算法的发展过程几乎贯穿了整个

作为最经典的排序算法之一, 快速排序几乎伴随了现代计算机科学的

作为历史悠久的经典排序算法

快速排序曾经是大部分语言默认提供的排序算法

早期的标准库中一般使用**快速排序**作为默认的排序算法, 例如早期STL中的sort函数
目前, Python和JDK中默认的排序算法为TIMSORT, TIMSORT的最坏情况要要好于快速排序并且结果稳定

自定义排序(<https://leetcode-cn.com/problems/custom-sort-string/submissions/>)

```python
    def customSortString(self, S: str, T: str) -> str:
        return ''.join(sorted(T, key=lambda x: S.find(x)))
```

opreator模块

[排序基础](https://www.cnblogs.com/whaben/p/6495702.html)

你可能会好奇, 为什么可以给函数传递处理规则, 这主要是因为python中的函数是被当作对象处理的, 任何实现了`__callable__`方法的实例都可以被当做函数来调用, 此外`lambda`表达式也可以被传递, 函数式编程入门

# 双指针

在循环中通过下标或指针逐个访问元素是遍历线性结构的常规方法. 但在某些情况下, 可以借助多个指针在一次遍历过程中实现多任务处理, 而[双指针（double pointers）](https://leetcode-cn.com/tag/two-pointers/)就是诸多方法中最朴素的一种. 根据遍历的方向不同, 可以将双指针方法分为处理对称结构或左右边界的**对撞指针**, 以及用于解决滑动窗口问题或验证容器结构的**快慢指针**.

所谓的对撞指针思想, 就是让指向序列首部的头指针$P_{head}$和指向尾部的尾指针$P_{tail}$在遍历过程中根据事先制定的边界条件向序列中间移动的过程, 一般被用于处理[验证回文串](https://leetcode-cn.com/problems/valid-palindrome/)、[反转字符串](https://leetcode-cn.com/problems/reverse-string/)、[有序数组找两数之和](https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/)等问题. 常用的**二分查找**算法就属于对撞指针思想的一种具体实现. 此外, 对撞指针也可以配合其他高级算法使用, 例如: 使用双指针加贪心策略可以轻松解决[救生艇](https://leetcode-cn.com/problems/boats-to-save-people/)问题.

```python
def numRescueBoats(self, people: List[int], limit: int) -> int:
    res, head, tail = 0, 0, len(people)-1
    people.sort()

    while head <= tail:
        if people[head] + people[tail] <= limit:
            head += 1  # 满足条件则最轻的乘客也能上船

        tail -= 1  # 始终让最重的乘客上船
        res += 1  # 救生艇数量

    return res
```

首先对数组升序排序, 头指针指向最轻的乘客, 尾指针指向最重的乘客. 由于限制了每个救生艇最多承载两名乘客, 因此问题可以转化为有限制的整数背包问题, 即采用重量优先的贪心策略. 当头指针和尾指针指向的乘客能共同上船时, 将两个指针向中间移动, 否则仅让尾指针向中间移动. 每次迭代都增加救生艇的数量, 当头尾指针相遇时就返回结果.

双指针的另一种用法是通过构造速度差来实现滑动窗口, 进而实现对区间数据的处理, 这就是快慢指针思想. 例如在[删除排序数组中的重复项](https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array/)问题中, 使用快慢指针可以完美实现原地删除:

```python
def removeDuplicates(self, nums: List[int]) -> int:
    slow, n = 0, len(nums)

    for fast in range(n):
        if nums[fast] != nums[slow]:
            slow += 1
            nums[slow] = nums[fast]

    return slow + 1
```

慢指针用于记录不同的元素, 而快指针则用于过滤重复元素. 由于整个列表是有序的, 因此当快指针与慢指针指向的值之间出现差异时, 则说明二者之间的元素都为需要删除的重复元素. 另一道与之相似的[分割数组](https://leetcode-cn.com/problems/partition-array-into-disjoint-intervals/)问题也可以用快慢指针求解:

```python
def partitionDisjoint(self, A: List[int]) -> int:
    res = 0
    fast_max = slow_max = A[0]

    for i in range(1, len(A)):
        fast_max = max(fast_max, A[i])  # 更新快指针
        if A[i] < slow_max:  # 右侧存在更小的值
            res = i  # 记录分割点下标
            slow_max = fast_max  # 更新慢指针

    return res + 1  # 长度 = 下标 + 1
```

上述问题中的慢指针用于记录当前左侧数组中最大值, 并在遍历过程中与右侧元素逐个对比, 而快指针则用于记录目前遍历过的最大值. 当右侧出现小于慢指针所指向值的元素时, 就需要扩展左侧数组到当前位置并更新慢指针. 这样就能保证左侧数组中的值始终小于右侧数组.

不难看出, 快慢指针的优势就在于通过一次遍历完成多个任务, 这能显然能够避免由多次迭代所导致的额外时间复杂度开销. 但相比于在数组中的应用, 快慢指针显然更适合于验证链表是否满足结构化性质或仅通过单次遍历修改链表结构, 例如: [判断链表中是否有环](https://leetcode-cn.com/problems/linked-list-cycle/)、[寻找链表的中间节点](https://leetcode-cn.com/problems/middle-of-the-linked-list/)、[判断链表是否相交](https://leetcode-cn.com/problems/intersection-of-two-linked-lists/)等. 详见[链表双指针](/2020/02/03/%E9%9B%86%E5%90%88%E4%B8%8E%E9%93%BE%E8%A1%A8/#%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88)专题.

# 二分查找

二分查找属于跳跃式对撞指针,

对序列型结构来说, 实现$O(n)$级别时间复杂度的线性查找算法显然不算是棘手的问题

作为对撞指针方法的特例, 二分查找

同时也是二叉查找树的灵感来源

二分查找的局限在于只能被用于有序结构的查找

根据当前边界与目标值的关系来移动左右指针

只能被用于有序

作为双指针类算法的最常见

必须有序

关键属性

二分查找的最基础和最基本的形式。
查找条件可以在不与元素的两侧进行比较的情况下确定（或使用它周围的特定元素）。
不需要后处理,因为每一步中,你都在检查是否找到了元素。如果到达末尾,则知道未找到该元素。

区分语法

初始条件：left = 0, right = length-1
终止：left > right
向左查找：right = mid-1
向右查找：left = mid+1

```python
def binarySearch(nums, target):
    if len(nums) == 0:
        return -1

    left, right = 0, len(nums) - 1
    while left <= right:
        mid = (left + right) // 2
        if nums[mid] == target:
            return mid
        elif nums[mid] < target:
            left = mid + 1
        else:
            right = mid - 1

    return -1
```

抽象二分查找
[寻找重复数](https://leetcode-cn.com/explore/learn/card/binary-search/215/more-practices-ii/858/)

[三种模板](https://leetcode-cn.com/explore/learn/card/binary-search/212/template-analysis/847/)

`bisect`模块

# 案例1: 分治算法

分治思想是并行计算的理论基础基础, 只有能被合理拆分并独立计算的任务才能被并行化处理

Karatsuba 算法

[分治算法](https://leetcode-cn.com/tag/divide-and-conquer/)

[例题](https://buptldy.github.io/2016/01/06/2016-01-06-Divide%20and%20Conquer/)

归并排序

快速傅里叶变换

[数组中的逆序对](https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/)

# 案例2: 贪心算法

所谓的贪心策略, 就是在求解问题的每个步骤时都做出当前情况下的**局部最优**选择. 显然, 使用这种重视局部而忽略整体的策略并不一定能得出全局最优解, 但对于满足**贪心选择性质**与**最优子结构性质**的问题来说, 自顶向下的贪心算法往往是最优选的解决方案. 在计算机科学领域, 许多经典问题的解决方案都是基于贪心策略制定的, 例如: [哈夫曼编码](https://coolshell.cn/articles/7459.html)、[单源最短路径](https://segmentfault.com/a/1190000009475858)、[最小生成树](https://oi-wiki.org/graph/mst/)等. 一般来讲, 证明贪心算法能够求解出全局最优解的难度要远高于设计该算法.

满足贪心选择性质是问题能够通过贪心算法求出全局最优解的[必要条件](https://www.zhihu.com/question/30469121)之一. 区别于自底向上求解重叠子问题的动态规划算法, 贪心算法通常以**自顶向下**的方式执行, 以迭代的方式根据事先制定的贪心策略作出一系列贪心选择, 每次迭代都会将当前所求的问题转化为规模更小的子问题. 所谓的贪心选择性质就是指所求问题的全局最优解可以通过对每个子问题做贪心选择而得出.

而隐含了全局最优解和子问题最优解之间**递推关系**的最优子结构性质, 则是问题能用贪心算法或动态规划求解的另一个必要条件. 贪心算法的自顶向下处理模式恰好避免了动态规划所主要解决的重叠子问题, 也就是说, 显式指定了下一步要求解的子问题的贪心策略天生具有避免重复计算的性质. 这样看来, 贪心算法其实是动态规划的一种特例.

在确定了问题适合使用贪心算法求解之后, 贪心策略的设计就成为了最核心的工作. 贪心策略必须具备**无后效性**, 即当前状态的决策不会影响后续状态对最优解的选择. 以经典的[部分背包问题](https://www.cnblogs.com/hapjin/p/5575109.html)为例, 题目要求我们向固定容量的背包中放入包含价值和重量两种属性的物品, 物品可以被拆分, 求背包所能承载的最大价值. 不难想出以下三种贪心策略:

* 按最大价值贪心: 贵重的物品优先放入背包, 目标函数增长最快
* 按最小重量贪心: 轻的物品优先放入背包, 尽可能地放入更多物品
* 按最大单位价值贪心: $单位价值=物品价值/物品重量$, 尽可能地放入单价最高的物品

大部分情况下, 贪心策略的制定是符合常识的. 显然在上述问题中, 采用按最大单位价值的贪心策略能够取得最优解. 选择恰当的贪心策略不仅能显著降低编码难度, 还能以更低的时间和空间复杂度解决问题. 例如在[跳跃游戏](https://leetcode-cn.com/problems/jump-game/)中, 最佳的贪心策略就是记录当前能达到的最远距离:

```python
def canJump(self, nums: List[int]) -> bool:
    rightmost, n = 0, len(nums)

    for i in range(n):
        if i <= rightmost:
            rightmost = max(rightmost, i+nums[i])
            if rightmost >= n-1: return True
        # else: break  # 可选剪枝

    return False
```

如果当前索引大于目前可达的最远距离, 则说明该索引位置之后的所有位置均不可达, 因此可以直接返回, 但由于[分支预测](https://www.jianshu.com/p/be389eeba589)机制的存在, 这种剪枝方式并不一定能提高处理效率. 总的来看, 使用贪心算法解决该问题的时间复杂度为$O(n)$, 空间复杂度为$O(1)$. 更复杂一些的[最小跳跃次数](https://leetcode-cn.com/problems/jump-game-ii/)问题, 则需要在原有贪心策略的基础上记录每个点能跳到的最远距离, 当索引到达最远距离时则应该增加跳跃次数:

```python
def jump(self, nums: List[int]) -> int:
    n = len(nums)
    rightmost = end = step = 0

    for i in range(n-1):
        if i <= rightmost:
            rightmost = max(rightmost, i+nums[i])
            if i == end:
                end = rightmost
                step += 1
    return step
```

贪心算法的另一类应用在于求解满足特定条件的序列, 例如[无限次买卖股票](https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock-ii/)问题就等价于求所有的递增子数组. 这个问题的贪心策略也符合常识, 当股票价格大于前一天买入的价格时就卖出股票, 显然这样可以保证收入最大化:

```python
def maxProfit(self, prices: List[int]) -> int:
    return sum(max(0, prices[i] - prices[i-1])
                for i in range(1, len(prices)))
```

而与之相似的[摆动序列](https://leetcode-cn.com/problems/wiggle-subsequence/)问题也可以转化为求交替出现的递增和递减数对的数量, 其贪心策略的核心在于过滤连续重复出现的相同类型数对:

```python
def wiggleMaxLength(self, nums: List[int]) -> int:
    up, down, n = 1, 1, len(nums)
    if n < 2: return n

    for i in range(1, n):
        if nums[i] > nums[i-1]:
            up = down + 1  # 过滤连续重复出现的上升对
        elif nums[i] < nums[i-1]:
            down = up + 1  # 过滤连续重复出现的下降对

    return max(up, down)
```

然而, 在解决某些问题时, 无论使用何种贪心策略都无法获得最优解. 例如在[柠檬水找零](https://leetcode-cn.com/problems/lemonade-change/)问题中, 假如用户支付的钞票面值并非柠檬水售价的倍数, 那么优先找零大面值钞票的贪心策略就会失效. 在这种情况下, 要么重新寻找贪心策略并证明其正确性, 要么使用更复杂但却更通用的动态规划算法, 这显著揭示了[贪心算法的局限性](https://www.zhihu.com/question/23995189).

总的来说, 贪心算法的优势就在于实现简单且时间复杂度和空间复杂度相对较低, 但严苛的应用条件以及繁琐的证明过程限制了其应用范围. 然而, 针对某些求出最优解的代价过于昂贵甚至无法通过图灵机计算模型求解的问题（NP-hard）, 利用贪心算法快速求出近似最优解就显得十分必要了.

# 案例3: 动态规划

分治算法求解问题时,每次产生的子问题并不总是新问题,有些子问题重复出现,这种性质称为子问题重叠性质。

在动态规划算法中,对于重复出现的子问题,只是在第一次遇到时执行求解过程,然后把求解结果保存在一个表格(可能是高维表格)中,再遇到这个子问题时,直接从表格中引用答案,从而避免重复计算,达到提高效率的目标。

需要提醒的是,子问题重叠性质不是动态规划适用的必要条件,但是如果该性质不满足时,动态规划方法与其他方法相比就不具备优势。

将复杂的原始问题拆分为一系列可独立求解的子问题就是**动态规划（Dynamic Programming）**的核心思想. 贪心算法过于关心局部最优而忽略了整体,

* 重叠子问题
* 最优子结构

根据图灵机的定义不难看出, 现代计算机中算法的本质是状态转移, 即从
求解动态规划问题的关键在于得出递推方程

动态规划是一种在数学、管理科学、计算机科学、经济学和生物信息学中使用的, 通过把原问题分解为相对简单的子问题的方式求解复杂问题的方法.

动态规划常常适用于有重叠子问题和最优子结构性质的问题，动态规划方法所耗时间往往远少于朴素解法。

动态规划背后的基本思想非常简单。大致上，若要解一个给定问题，我们需要解其不同部分（即子问题），再根据子问题的解以得出原问题的解。动态规划往往用于优化递归问题，例如斐波那契数列，如果运用递归的方式来求解会重复计算很多相同的子问题，利用动态规划的思想可以减少计算量。

通常许多子问题非常相似，为此动态规划法试图仅仅解决每个子问题一次，具有天然剪枝的功能，从而减少计算量：一旦某个给定子问题的解已经算出，则将其记忆化存储，以便下次需要同一个子问题解之时直接查表。这种做法在重复子问题的数目关于输入的规模呈指数增长时特别有用。

爬楼梯

[最小花费爬楼梯](https://leetcode-cn.com/problems/min-cost-climbing-stairs/)

<https://leetcode-cn.com/explore/interview/card/top-interview-questions-easy/23/dynamic-programming/54/>

折木棍/剪绳子(对比数学优化与策略)

[礼物的最大价值](https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/)

状态转移方程

\begin{equation}
dp(i, j) = \max(dp(i - 1, j), dp(i, j - 1)) + grid[i][j]
\end{equation}

# 案例4: 子序列与子串问题

滑动窗口与动态规划

[最长回文子序列](https://leetcode-cn.com/problems/longest-palindromic-subsequence/)

[最长回文子串](https://leetcode-cn.com/problems/longest-palindromic-substring/)

# 参考内容

* [数组与字符串](https://leetcode-cn.com/explore/featured/card/array-and-string/)
* [动态规划](https://leetcode-cn.com/tag/dynamic-programming/)
