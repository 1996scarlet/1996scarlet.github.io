---

layout:     post
title:      高性能程序设计（六）
subtitle:   网络层的数据与控制
date:       2019-12-06 10:00:00
author:     "Remilia Scarlet"
header-img: "2020/06/06/t6XpBn.jpg"
catalog: true
mathjax: true
tags:
    - Java

---

# 网络层的设备与协议

网络层的作用可以简要描述为主机级别的数据传输. 相比于端口到端口的传输层协议, 网路层协议更关注于如何将数据分组**尽力交付**到目标主机上. 在因特网中, 网络层协议不关心数据能否被交付, 能否有序交付, 传输的时延与带宽, 是否安全等, 只会尽力而为.

路由器是网络层中最重要的设备. 由于现实世界中的网络环境一般比较复杂, 数据分组需要经过层层路由才能到达目标主机, 因此如何正确地转发分组以及选择合适的传输路线就成为了网络层需要着重考虑的问题.

* **转发(forwarding):** 是指将分组从一个输入链路接口转移到适当的输出链路接口的路由器级别的动作. 转发动作一般由硬件直接控制(烧录好的FPGA), 处理时间为纳秒级别, 归属于路由器处理时延的一部分.
* **路由选择(routing):** 是指确定分组从源到目的地所需要经过路径的过程. 传统的路由选择方式是在分组到达某个路由器之后, 才根据当前路由器所记录的转发表(forwarding table)来确定需要转发到哪条链路, 即下一个目标是哪个路由器或主机, 相当于开车时在每个十字路口都问路. 而相对前沿的研究方向是抽取路由器的控制功能, 让控制中台来指示路由器向哪条链路转发数据, 免去了网络层设备因维护路由表而产生的额外开销, 可类比于智能导航APP的路径规划功能. 这种结构被称为软件定义网络(Software-Defined Networking, SDN).

## 路由器的工作原理

路由选择与路由表的管理完全由软件控制, 因此被称为控制平面. 分组的转发完全由硬件控制, 因此被称为数据平面. 路由器的结构可被抽象为4个部分:

* 输入端口: 负责从链路中读取数据分组
* 输出端口: 负责将数据分组放入链路
* 交换结构: 负责将从输入端口得到的数据分组转发到正确的输出端口. 交换结构的实现包括内存方式, 总线方式, 端口互联方式. 内存方式最简单, 但由于总线的限制, 经过共享内存的总线每次只能执行一个内存读写操作, 因此系统总吞吐量要小于内存带宽的一半. 去掉共享内存就可以变为基于总线的分组交换, 这种方式更适合于小范围的分组交换, 因为没有共享内存作为缓冲会导致系统的吞吐量进一步下降. 而端口互联方式实现起来要更加复杂, 但吞吐量要显著好于上述两种方案, 一般被用于高端路由器中.
* 路由选择处理器: 负责控制平面的业务逻辑, 即维护转发表, 根据转发表计算正确地输出端口. 在SDN中, 路由选择处理器负责与控制中台通信, 接受云端计算好的转发信息.

传统的基于路由表的路由选择方法无法有效利用全局信息, 例如某个路径拥塞时, 路由表无法迅速响应并调整; 又例如某个应用需要低延时, 而某个应用却需要高吞吐量, 那么传统路由表就无法进行数据分组的智能分配. 而SDN却可以根据整个网络的流量分布, 动态调整数据分组的传输路径, 更合理地分配网络资源.

使用路由表的好处在于实现简单且处理时间较短. 路由表的匹配基于**最长前缀匹配规则**, 即在路由表中寻找最长的匹配项.

无论是输入还是输出端口, 在信道拥塞时都会出现排队现象. 路由器为了防止缓存溢出会丢弃在队尾的元素. 使用恰当的分组调度策略能够降低排队阻塞的风险.

* 先进先出: 最基本的分组调度策略
* 优先权排队: 使用优先级队列实现, 队列中的元素会根据优先级排队. 某些游戏网卡会将游戏数据分组标注为高优先级, 这些分组在支持优先权排队的路由器中能够被优先转发, 显著降低排队延时.
* 循环的加权公平排队: 如果只有一个队列, 应用可以通过给分组标注高优先级来完全抢占路由器资源. 公平起见, 路由器可以提供多个优先级队列以支持被标记为不同类型的数据分组. 循环地取出每个优先级队列中的元素即可实现公平的资源占用.

## 路由选择算法

最简单的路由选择算法模型就是最短路径算法, 而根据实际传输要求, 可能会添加如: 最少经过节点, 最少丢包率等约束条件. 目前在因特网中常用如下算法:

* 链路状态算法(Link State, LS): 典型的集中式路由选择算法, 需要事先获取从源到目标节点中间所有可能经过的链路的开销.
* 距离向量算法(Distance-Vector, DV): 是分散式路由选择算法的代表, 每个路由节点仅需要记录与其直接相连的链路开销即可.

两种算法各有优劣, 一般会根据网络环境选择合适的算法.

## IP:网际协议

目前广泛使用的IPv4协议定义在[RFC 791](https://tools.ietf.org/html/rfc791)中, 其报文格式如下:

* 版本, 首部长度, 服务类型, 数据报长度
* 16比特标识, 标志, 13比特片偏移(IP分片)
* 寿命, 上层协议, 首部校验和
* 32比特源IP地址
* 32比特目的IP地址
* 选项(不定长)
* 数据

IP报文由于携带了数据导致其大小不确定, 然而由于链路层协议的MTU限制, 数据链路能承载的数据分组有严格的限制, 因此较大的IP报文需要分片传输. 根据报文首部的**标志**和**片偏移**字段能够确定当前数据分组是整个IP报文的哪部分, 也能用于检测是否发生了分片丢失. 最后一个片的标志比特被设为0, 而其他片的标志比特都是1.

IPv4的地址长度为32比特, 可容纳约40亿个地址. 日常使用的格式为8比特为一组的点分十进制. 为了更好地利用有限的IP资源, 以及更方便地对相似网络设备进行管理, 需要通过[子网划分](https://baike.baidu.com/item/%E5%AD%90%E7%BD%91%E5%88%92%E5%88%86)来隔离多组主机:

* A类地址: 掩码/8, 第一个比特是0, 即`0.0.0.0~127.255.255.255`, 占所有地址的1/2
* B类地址: 掩码/16, 前两个比特为10, 即`128.0.0.0~191.255.255.255`, 占所有地址的1/4
* C类地址: 掩码/24, 前三个比特为110, 即`192.0.0.0~223.255.255.255`, 占所有地址的1/8
* D类地址: 前四个比特为1110, 即`224.0.0.0`到`239.255.255.255`, 用于多播
* E类地址: 前五个比特为11110, 即`240.0.0.0`到`247.255.255.255`, 保留地址

主机的IP地址可以手动设置, 但在小型局域网中一般采用动态主机配置协议(Dynamic Host Configuration Protocol, DHCP)实现主机的即插即用. DHCP的协商步骤如下:

* DHCP服务器发现. 新加入的主机需要向DHCP服务器请求自己的IP地址, 但由于新加入的主机不仅不知道自己的IP, 也不知道DHCP服务器的IP, 因此需要构建一个UDP广播报文. 广播报文的目标IP地址需要填写为255.255.255.255, 端口填写为DHCP服务默认的67, 源IP地址填写0.0.0.0. 将该UDP报文递交给网路层并封装为IP报文后就可以顺着链路广播到局域网中的所有主机, 该报文也被称为**DHCP发现报文(DHCP discover message)**.
* DHCP服务器提供. 当DHCP服务器接收到DHCP发现报文时, 会向主机返回**DHCP提供报文(DHCP offer message)**. 由于目前新加入的主机仍未获得IP地址, 服务器在响应DHCP提供报文时仍需要使用广播地址. DHCP提供报文中会标注当前服务器的IP, 能够提供给新主机的IP, 租用时间等信息. 而由于局域网中可能存在多个能够提供DHCP服务的服务器, 新主机可能收到多个DHCP提供报文.
* DHCP请求. 新主机从返回的多个DHCP提供报文中挑选最想要的IP地址, 并给提供该IP的服务器返回**DHCP请求报文(DHCP request message)**.
* DHCP ACK. 服务器确认主机的请求报文, 返回**DHCP ACK报文(DHCP ACK message)**.

DHCP的协商流程可简要概括为: 新主机向局域网发送广播, 多个DHCP服务器返回可用的IP地址与租用时间, 主机挑选一个IP地址并告知提供该IP的服务器, 服务器确认该请求. DHCP协议的缺陷在于, 每当节点连接到一个新子网, 都需要从DHCP服务器获取新的IP地址, 这显著提升了移动终端对网络切换的敏感程度.

尽管**网络地址转换(Network Address Translation, NAT)**技术的广泛使用让IPv4地址用尽的时限得以推迟, 但对新一代IP协议的研究仍有其必要性. 以ST-2协议为基础的IPv5协议早在20世纪80年代就被提出, 旨在提升IPv4对流式数据的处理效率. 但由于其地址长度仍为32位, 因此没有被正式采用, 部分功能被并入目前使用的IPv4中. 而IPv6则简单粗暴地将地址长度提升到128位, 在可以预见的未来里, 这种数量级的地址完全没有用尽的风险. IPv6的数据报格式如下:

* 版本, 流量类型, 流标签
* 有效载荷长度, 下一个首部, 跳限制
* 源地址
* 目的地址
* 数据

与IPv4显著不同的是, IPv6去掉了首部校验和字段, 将报文的正确性验证交由运输层处理; IPv6还禁止在中间路由器上进行分片与重新组装, 让这种操作只能在源与目的地执行, 一旦中间路由无法处理过大的分组就会给发送方返回ICMP差错报文, 提示分组过大; IPv6通过在下一个首部字段中指明扩展头/TCP/UDP而实现首部定长. 可以看出, IPv6的整体改进思路在于提升处理效率, 在中间路由器分片与组装需要重新计算校验和, 这些都是十分耗时的操作.

## ICMP:因特网控制报文协议

差错报告是ICMP的最典型应用场景. 例如: 向目标机器发送HTTP请求时, 网路层的IP报文到达某个路由节点时发现目标链路暂时不可用(服务器宕机), 该路由器就会向发送方回传ICMP报文并指示错误.

尽管ICMP与IP协议同属与网络层, 但ICMP的层次略高于IP, ICMP的报文需要被IP承载. ICMP报文包含一个类型字段与一个编码字段. 常用的ping程序就是通过构建类型为8, 编码为0的ICMP报文来向服务器发送回显请求; 服务器则会返回类型为0, 编码为0的回显回答. ICMP也可以用于拥塞控制, 通过向源主机发送类型为4, 编码为0的ICMP报文可以限制其发送速率. ICMP很少被用于拥塞控制, 因为运输层的TCP协议已经实现了非常完善的拥塞控制机制.

# 链路层与局域网

在计算机网络中, 主机、路由器、交换机甚至是WiFi接入点都属于**节点(node)**, 而**链路(link)**则被定义为沿着通信路径连接相邻节点的通信信道. 链路层协议更关心的是如何将数据帧沿着链路从一个节点发送到另一个节点.如果将北京和上海比作节点, 那么北京到上海的航线就是链路, 而飞机就是链路层协议, 飞机上的乘客就是数据帧.

链路层协议一般在网卡及其驱动中实现. 链路层协议可能提供以下服务:

* 成帧: 大部分链路层协议会将网路层传来的IP报文封装为数据帧, 封装的格式完全取决于链路的种类以及所采用的链路层协议.
* 链路接入控制: 媒体访问控制(Medium Access Control, MAC)协议规定了帧在链路上传输的规则. MAC协议用于协调多个节点在共享单个广播链路时的帧传输顺序, 但对于点对点的链路来说, MAC协议的用处不大.
* 可靠交付: 保证数据链路能够无差错地传递网络层的数据报. 与运输层的可靠交付服务类似, 链路层的可靠交付服务也是通过确认和重传来保证的. 大部分链路层协议都不提供可靠交付服务, 但由于无线链路通常会产生高比特差错率的数据帧, 因此WiFi协议提供了可靠交付服务. 而在比特差错率较低的光纤链路中, 提供可靠交付服务就显得无关紧要.
* 差错检测和纠正: 传输过程中的信号衰减或电磁噪声干扰可能导致数据比特出现差错. 通过在帧首部添加校验码可以让节点在接收数据帧时进行差错检测, 如果出现差错就让发送方重传. 此外, 借助特殊的算法也可以直接在接收方实现差错纠正.

## 差错检测和纠正技术

一般而言, 差错检测和纠正技术越复杂, 导致的开销就越大, 但检测和纠正效果也越好, 在实际使用中需要根据实际网络环境与上层应用的实际需求来挑选差错检测和纠正算法.

* 校验和: 最简单的差错检测方法, 将报文中的数据比特相加, 与校验和对比即可. TCP/UDP通过在报文首部添加校验和字段来判断报文是否出现差错, 因为传输层协议完全是由软件实现的, 需要简单快速.
* 循环冗余检测: 链路层协议的大部分功能可以交由专门的硬件芯片实现, [循环冗余检测(Cyclic Redundancy Check, CRC)编码](https://www.eet-china.com/mp/a27912.html)就是最好的例子. 尽管CRC的效果显著强于校验和, 但在传输层通过软件层面进行CRC编码将耗费大量资源并产生可观的延迟; 而在链路层则可以通过特殊设计的CRC芯片实现超高速CRC编码.  
* 奇偶校验: 通过在原始数据后添加奇偶校验位来实现. 奇偶校验位记录的是数据中比特为1的位的数量是否为奇数. 显然, 当多个比特出错时, 奇偶校验的精确度将显著下降, 因此推出了二维奇偶校验方案. 二维奇偶校验不仅可以检测是否出现差错, 通过对出错行和列的定位能够直接找到出错的比特, 从而进行差错纠正. 这种在接收方检测和纠错的方法被称为前向纠错(Forward Error Correction, FEC).

## 多路访问链路和协议

帧碰撞会导致多个数据帧报废, 因此需要对多路访问进行控制.

* 信道划分协议: 时分多址(TDMA), 频分多址(FDMA), 码分多址(CDMA)
* 随机接入协议: 时隙ALOHA, 纯ALOHA, 载波侦听多路访问(Carrier Sense Multiple Access, CSMA), 带有碰撞检测的CSMA(CSMA with Collision Detection. CSMA/CD). 载波侦听就是监听当前信道中是否有其他数据帧在传递, 如果有就等待. 碰撞检测就是当发现再传输过程中出现碰撞时就主动退避.
* 轮流协议: 论询协议(中心化, 中心主机控制其他节点的数据传输), 令牌传递协议(去中心化, 节点轮流持有令牌, 有令牌的节点才可以发送数据)

## 地址解析协议

主机名是主机在应用层的地址, IP地址是主机在网络层的地址, 而MAC地址则是主机在链路层的地址. 尽管IP协议被广泛使用, 但在某些特殊的网络中会使用IPX, DECnet等其他网路层协议, 因此路由器接口使用网络层地址+MAC的方式标记目标主机.

在同一个子网中, 需要使用**地址解析协议(Address Resolution Protocol, ARP)**将目标主机的IP地址解析为MAC地址, 从而实现链路级别的目标主机定位. 在主机或路由器中会维护ARP表, 用于记录当前子网中的IP地址与MAC地址的映射关系. 每个表项存在过期时间, 一般为20分钟. ARP协议可以被看作是跨越链路层和网络层的协议.

跨子网通信步骤, 假设从子网A中的1.1.1.1主机向子网B中的2.2.2.2主机发送数据帧:

* 将数据包发给路由器: 数据帧中需要填写目标主机的IP地址以及路由器的MAC地址. 如果填写目标主机的MAC地址, 则在子网A中由于找不到该MAC地址, 因此链路层会丢弃该分组.
* 路由器将数据包发给目标主机: 分组到达路由器之后, 路由器分析出目标IP位于子网B中, 因此会通过ARP协议在子网B中寻找对应的MAC, 将目标主机的MAC写入数据帧后交由链路层发送.

## 链路层交换机

集线器工作于物理层, 交换机工作于链路层, 路由器工作于网络层. 每层的设备对其上层都是透明的, 网络层的路由器和主机感受不到交换机的存在. 交换机为每个输出接口设有缓存, 防止数据帧的输出速率超过链路载荷.

交换机能够最大程度地避免以太网中的数据碰撞, 实现链路级别的数据隔离以及监测链路层数据帧的状态. 交换机能够检测输出链路上是否存在正在发送的帧, 如果有就将输出数据暂时写入输出接口的缓存, 等到不会发生冲突时在发送. 尽管这种做法会产生微量的延迟, 但是优势在于不会降低原有链路的传输速率, 也不会因帧冲突而造成带宽浪费. 交换机的总带宽是所有接口速率的和, 而集线器的输出接口会平分输入接口的带宽. 交换机能够隔离数据链路, 接入同一台交换机的链路的速率和媒介都可能是不相同的. 此外, 交换机是非侵入设备, 在原有连接的基础上增加交换机不会产生任何影响. 如果交换机检测到某个主机工作异常, 会在交换机内部主动断开该设备的输入或输出接口, 并反馈状态.

过滤与转发是交换机的核心功能. **转发(forwarding)**是决定输入的数据帧应该被传递到哪个输出接口; **过滤(filtering)**用于决定数据帧应该被转发到某个接口还是直接丢弃; 这两个功能的实现都基于**交换机表(switch table)**.

交换机表记录的是MAC地址与端口的映射关系, 通过**自学习(self-learning)**以及给每条记录设置过期时间来实现自动更新. 假设目的MAC地址为$m$的帧从交换机接口$x$到达:

* 如果表中没有地址为$m$的记录. 交换机会向$x$之外的其他接口转发该帧的副本, 即广播该帧.
* 如果表中地址为$m$的记录指向接口$x$. 由于输入和输出接口相同, 交换机会过滤该帧.
* 如果表中地址为$m$的记录指向接口$y$, 且$y \ne x$. 交换机会将该帧转发到接口$y$.

**交换机毒化(switch poisoning)**是最典型的针对交换机的攻击手段. 攻击者向交换机发送大量具有不同伪造源MAC地址的分组, 填满交换机表, 从而让交换机只能以广播的形式将报文发送到合法主机, 而攻击者就能嗅探到这些广播报文. 但由于伪造源MAC地址的成本过高, 对交换机的攻击性价比远比不上攻击路由器.

交换机与路由器的区别:

* 层次不同: 交换机位于链路层, 路由器位于网路层
* 寻址方式不同: 交换机依据MAC地址寻址, 而路由器依据IP地址寻址
* 部署方式不同: 交换机即插即用, 而路由器需要设置

| | 集线器 | 交换机 | 路由器 |
| ----- | --------- | ----------- | ----------- |
| 即插即用 | 有 | 有 | 无 |
| 流量隔离 | 无 | 有 | 有 |
| 优化路由 | 无 | 无 | 有 |

# 案例1: Web页面请求的过程

# 案例2: 网络安全

通过因特网传输的数据分组可能会被攻击者窃听, 甚至直接修改数据分组的内容后再发给接收方. 这种中间人攻击可能发生在WEB网络通信的任何阶段, 例如: 对DNS或HTTP的劫持. 安全通信(secure communication)需要具备以下特性:

* 机密性(confidentiality). 仅有发送方和预期的接收方能够理解传输报文的内容. 只要加密手段足够复杂, 即使窃听者截获了报文, 也无法在有生之年暴力破解该报文.
* 报文完整性(message integrity). 预期的接收方能够完整无误地接收到发送方传输的报文. 窃听者截获报文之后, 即使无法破解, 也可以篡改其中的比特位或新增数据, 需要借助校验和等技术来保证传输数据的完整性.
* 端点鉴别(end-point authentication). 发送方和接收方需要具备能够确定对方是预期终端的能力.
* 运行安全性(operational security). 通信链路中的主机具备自主防护能力. 通过防火墙等设备反制网络攻击.

密码学领域的做法是, 通过加密算法(encryption algorithm)将明文(plaintext)报文转换为密文(ciphertext). 现代密码系统中一般采用通用的加密算法, 这些算法对发送方, 接收方甚至是攻击者都是已知的.

加密的关键在于被称为**密钥(key)**的隐藏信息. 以$A$和$B$代表通信双方, 令它们拥有的密钥分别为$K_{A}$和$K_{B}$. 假设使用SHA-256作为加密算法, 加密函数为${S}\_{256}$, 解密函数为$\hat{S}\_{256}$.以主机$A$向主机$B$发送分组$m$的过程为例:

* 主机$A$构造加密报文: $\hat{m} = {S}\_{256}(m, K\_{A})$
* 主机$B$使用对应的解密算法解密报文: $m = \hat{S}\_{256}(\hat{m}, K\_{B})$

在**对称密钥系统**中, $K_{A}$与$K_{B}$相同且理论上只有通信双方可知. 对称加密算法一般是分块加密的, 常见的有DES, 3DES, AES. 而在**非对称密钥系统**中, 每个通信方分别持有由公钥和私钥构成的密钥对, 其中公钥$K_P$是公开的, 而私钥则理论上只有对应的主机可知. 非对称加密的一般流程如下:

* 主机$A$随机生成私钥$K_A$, 并向主机$B$请求公钥$K_P$
* 主机$B$返回公钥$K_P$,
* 主机$A$根据公钥$K_P$加密自己的私钥$K_A$, 并将加密结果发送给主机$B$
* 主机$B$根据私钥$K_B$解密报文, 得到主机$A$的私钥$K_A$

![非对称加密流程](/img/RSA.png)

上述过程成立的前提是: 使用主机$B$提供的公钥$K_P$加密后的数据只能被主机$B$的私钥$K_B$解密, 这样主机$A$的私钥才可以安全地传输到主机$B$. 在之后的通信过程中, 主机$A$和主机$B$都使用私钥$K_A$加密或解密数据. RSA是最经典的非对称加密算法, 但是速度较慢.

在机密性已经被保证的前提下, 需要验证报文的完整性以确保数据的发送源是期望用户, 以及数据在传输过程中没有被篡改. 通过使用密码散列函数, 报文鉴别码, 数字签名等手段可以最大程度地保证报文完整性.

公钥认证 CA 证书 端点鉴别

TCP协议在设计之初并没有考虑安全性, 而随着因特网环境的日渐恶化, 被称为**安全套接字层(Secure Socket Layer, SSL)**的TCP安全强化技术逐渐成为了实际应用中的标准, 并最终以**传输层安全性(Transport Layer Security, TLS)**的形式收录于[RFC 4346](https://tools.ietf.org/html/rfc4346).

尽管SSL完全在应用层中实现, 但从逻辑角度看, 仍然可以将SSL视作位于应用层与传输层之间的**子层(sub-layer)**. 应用层与SSL之间通过安全套接字(Secure Socket, SS)传递数据, SSL与运输层之间通过普通套接字传递数据. SSL的作用在于, 向应用层提供了SS接口, 能够加密应用要传递的数据; 向下保留了原始的socket传递方式, 将加密后的数据以二进制的形式放入socket交给TCP去运输, 保证了兼容性.

在通过三次握手建立TCP连接之后, 还需要再经过三次握手建立SSL连接, 在连接过程中协商所采用的加密算法以及得到主密钥(MS).

* 客户发送它支持的加密算法列表, 以及一个客户端不重数
* 服务器将选择的对称加密算法, 非对称加密算法, MAC算法, CA证书以及服务端不重数返回给客户.
* 客户端验证该证书的合法性, 并从中提取服务器的公钥, 然后生成**前主密钥(Pre-Master Secret, PMS)**. 接下来使用公钥加密PMS, 并将加密后的PMS发送给服务器.
* 服务器解密报文得到PMS, 这时客户端和服务器都已经持有了PMS, 因此其升级为**主密钥(Master Secret, MS)**

其中, **不重数**用于防止**连接重放攻击**. 由于握手的前两步是以明文方式传递数据, 因此为了避免中间人攻击, 除了发送不重数之外, 客户端与服务端还需要额外交换并确认握手过程中所有报文的MAC地址. 在SSL断开时, 如果直接将TCP的FIN报文断开视为连接结束的标志则容易引发截断攻击(truncation attack), 即攻击者向服务器发送明文FIN报文让TCP连接提前断开. SSL标准中给出的方案是在SSL记录的类型字段中设置连接关闭标签.
